<FrameworkSwitchCourse {fw} />

# ì§ˆì˜ ì‘ë‹µ[[question-answering]]

{#if fw === 'pt'}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section7_pt.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section7_pt.ipynb"},
]} />

{:else}

<CourseFloatingBanner chapter={7}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section7_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter7/section7_tf.ipynb"},
]} />

{/if}

ì§ˆì˜ì‘ë‹µì„ ì‚´í´ë³´ëŠ” ì‹œê°„! ì´ ì‘ì—…ì€ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ì œê³µë˜ì§€ë§Œ ì´ ì„¹ì…˜ì—ì„œ ì§‘ì¤‘ì ìœ¼ë¡œ ë‹¤ë£° ì‘ì—…ì€ *ì¶”ì¶œì * ì§ˆë¬¸ ë‹µë³€ì´ë¼ê³  í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ë¬¸ì„œì— ëŒ€í•œ ì§ˆë¬¸ì„ ì œê¸°í•˜ê³  ë¬¸ì„œ ìì²´ì˜ _í…ìŠ¤íŠ¸ ë²”ìœ„_ì— ëŒ€í•œ ë‹µë³€ì„ ì‹ë³„í•˜ëŠ” ê²ƒì´ í¬í•¨ë©ë‹ˆë‹¤.

<Youtube id="ajPx5LwJD-I"/>

ìš°ë¦¬ëŠ” Wikipedia ê¸°ì‚¬ ì„¸íŠ¸ì— ëŒ€í•´ í¬ë¼ìš°ë“œ ì‘ì—…ìê°€ ì œê¸°í•œ ì§ˆë¬¸ìœ¼ë¡œ êµ¬ì„±ëœ [SQuAD ë°ì´í„°ì„¸íŠ¸](https://rajpurkar.github.io/SQuAD-explorer/)ì—ì„œ BERT ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì˜ˆì¸¡ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì œê³µë©ë‹ˆë‹¤.

<iframe src="https://course-demos-bert-finetuned-squad.hf.space" frameBorder="0" height="450" title="Gradio app" class="block dark:hidden container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>


ì´ëŠ” ì‹¤ì œë¡œ ì´ ì„¹ì…˜ì— í‘œì‹œëœ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ë˜ê³  í—ˆë¸Œì— ì—…ë¡œë“œëœ ëª¨ë¸ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. [ì—¬ê¸°](https://huggingface.co/huggingface-course/bert-finetuned-squad?context=%F0%9F%A4%97+Transformers+is+backed+by+the+three+most+popular+deep+learning+libraries+%E2%80%94+Jax%2C+PyTorch+and+TensorFlow+%E2%80%94+with+a+seamless+integration+between+them.+It%27s+straightforward+to+train+your+models+with+one+before+loading+them+for+inference+with+the+other.&question=Which+deep+learning+libraries+back+%F0%9F%A4%97+Transformers%3F)ì—ì„œ ì°¾ì•„ë³´ê³  ì˜ˆì¸¡ì„ ë‹¤ì‹œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


<Tip>

ğŸ’¡ BERTì™€ ê°™ì€ ì¸ì½”ë” ì „ìš© ëª¨ë¸ì€ "Transformer ì•„í‚¤í…ì²˜ë¥¼ ë°œëª…í•œ ì‚¬ëŒì€ ëˆ„êµ¬ì…ë‹ˆê¹Œ?"ì™€ ê°™ì€ ì‚¬ì‹¤ì ì¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì¶”ì¶œí•˜ëŠ” ë° íƒì›”í•œ ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ "í•˜ëŠ˜ì€ ì™œ íŒŒë€ìƒ‰ì¸ê°€ìš”?"ì™€ ê°™ì€ ê°œë°©í˜• ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ ê²°ê³¼ê°€ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë³´ë‹¤ ê¹Œë‹¤ë¡œìš´ ê²½ìš°ì—ëŠ” ì¼ë°˜ì ìœ¼ë¡œ T5 ë° BARTì™€ ê°™ì€ ì¸ì½”ë”-ë””ì½”ë” ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ [í…ìŠ¤íŠ¸ ìš”ì•½](/course/chapter7/5)ê³¼ ë§¤ìš° ìœ ì‚¬í•œ ë°©ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ í•©ì„±í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìœ í˜•ì˜ *ìƒì„±ì * ì§ˆë¬¸ ë‹µë³€ì— ê´€ì‹¬ì´ ìˆë‹¤ë©´ [ELI5 ë°ì´í„° ì„¸íŠ¸](https://huggingface.co/datasets/eli5)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ [ë°ëª¨](https://yjernite.github.io/lfqa.html)ë¥¼ í™•ì¸í•´ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤.

</Tip>

## ë°ì´í„° ì¤€ë¹„[[preparing-the-data]]

ì¶”ì¶œì  ì§ˆë¬¸ ë‹µë³€ì„ ìœ„í•œ í•™ë¬¸ì  ë²¤ì¹˜ë§ˆí¬ë¡œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ì„¸íŠ¸ëŠ” [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)ì´ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì´ë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤. ë‹µë³€ì´ ì—†ëŠ” ì§ˆë¬¸ì„ í¬í•¨í•˜ëŠ” ë” ì–´ë ¤ìš´ [SQuAD v2](https://huggingface.co/datasets/squad_v2) ë²¤ì¹˜ë§ˆí¬ë„ ìˆìŠµë‹ˆë‹¤. ìì‹ ì˜ ë°ì´í„°ì„¸íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ ì—´, ì§ˆë¬¸ ì—´, ë‹µë³€ ì—´ì´ í¬í•¨ë˜ì–´ ìˆëŠ” í•œ ì•„ë˜ ë‹¨ê³„ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### SQuAD ë°ì´í„°ì„¸íŠ¸[[the-squad-dataset]]

í‰ì†Œì™€ ê°™ì´ `load_dataset()` ë•ë¶„ì— ë‹¨ í•œ ë‹¨ê³„ë¡œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ìºì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
from datasets import load_dataset

raw_datasets = load_dataset("squad")
```

ê·¸ëŸ° ë‹¤ìŒ ì´ ê°œì²´ë¥¼ ì‚´í´ë³´ê³  SQuAD ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
raw_datasets
```

```python out
DatasetDict({
    train: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 87599
    })
    validation: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 10570
    })
})
```

`context`, `question`, `answers` í•„ë“œì— í•„ìš”í•œ ëª¨ë“  ê²ƒì´ ìˆëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ë¯€ë¡œ í›ˆë ¨ ì„¸íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œì— ëŒ€í•´ ì´ë¥¼ ì¸ì‡„í•´ ë³´ê² ìŠµë‹ˆë‹¤.

```py
print("Context: ", raw_datasets["train"][0]["context"])
print("Question: ", raw_datasets["train"][0]["question"])
print("Answer: ", raw_datasets["train"][0]["answers"])
```

```python out
Context: 'Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend "Venite Ad Me Omnes". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'
Question: 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'
Answer: {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}
```

`context` ë° `question` í•„ë“œëŠ” ì‚¬ìš©ì´ ë§¤ìš° ê°„ë‹¨í•©ë‹ˆë‹¤. `answers` í•„ë“œëŠ” ë‘ í•„ë“œê°€ ëª¨ë‘ ëª©ë¡ì¸ ì‚¬ì „ì„ ì œê³µí•˜ë¯€ë¡œ ì¡°ê¸ˆ ë” ê¹Œë‹¤ë¡­ìŠµë‹ˆë‹¤. ì´ëŠ” í‰ê°€ ì¤‘ 'ìŠ¤ì¿¼ë“œ' ì¸¡ì •í•­ëª©ì—ì„œ ì˜ˆìƒë˜ëŠ” í˜•ì‹ì…ë‹ˆë‹¤. ìì‹ ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë‹µë³€ì„ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ëŠ” ê²ƒì— ëŒ€í•´ ê±±ì •í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. `text` í•„ë“œëŠ” ë‹¤ì†Œ ëª…í™•í•˜ë©° `answer_start` í•„ë“œì—ëŠ” ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê° ë‹µë³€ì˜ ì‹œì‘ ë¬¸ì ì¸ë±ìŠ¤ê°€ í¬í•¨ë©ë‹ˆë‹¤.

í›ˆë ¨ ì¤‘ì—ëŠ” ê°€ëŠ¥í•œ ë‹µì´ í•˜ë‚˜ë¿ì…ë‹ˆë‹¤. `Dataset.filter()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ë‹¤ì‹œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
raw_datasets["train"].filter(lambda x: len(x["answers"]["text"]) != 1)
```

```python out
Dataset({
    features: ['id', 'title', 'context', 'question', 'answers'],
    num_rows: 0
})
```

ê·¸ëŸ¬ë‚˜ í‰ê°€ë¥¼ ìœ„í•´ ê° ìƒ˜í”Œì— ëŒ€í•´ ì—¬ëŸ¬ ê°€ì§€ ê°€ëŠ¥í•œ ë‹µë³€ì´ ìˆìœ¼ë©° ì´ëŠ” ë™ì¼í•˜ê±°ë‚˜ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
print(raw_datasets["validation"][0]["answers"])
print(raw_datasets["validation"][2]["answers"])
```

```python out
{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}
{'text': ['Santa Clara, California', "Levi's Stadium", "Levi's Stadium in the San Francisco Bay Area at Santa Clara, California."], 'answer_start': [403, 355, 355]}
```

í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ëŠ” ëª¨ë‘ ğŸ¤— ë°ì´í„° ì„¸íŠ¸ ì¸¡ì •í•­ëª©ìœ¼ë¡œ ë§ˆë¬´ë¦¬ë˜ë¯€ë¡œ ìì„¸íˆ ë‹¤ë£¨ì§€ ì•Šê² ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ê°„ëµí•˜ê²Œ ì„¤ëª…í•˜ë©´ ì¼ë¶€ ì§ˆë¬¸ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ ê°€ëŠ¥í•œ ë‹µë³€ì´ ìˆìœ¼ë©° ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì˜ˆì¸¡ëœ ë‹µë³€ì„ ëª¨ë“  ì§ˆë¬¸ê³¼ ë¹„êµí•©ë‹ˆë‹¤. í—ˆìš©ë˜ëŠ” ë‹µë³€ì„ ì„ íƒí•˜ê³  ìµœê³  ì ìˆ˜ë¥¼ ë°›ìœ¼ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´ ì¸ë±ìŠ¤ 2ì˜ ìƒ˜í”Œì„ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```py
print(raw_datasets["validation"][2]["context"])
print(raw_datasets["validation"][2]["question"])
```

```python out
'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the "golden anniversary" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as "Super Bowl L"), so that the logo could prominently feature the Arabic numerals 50.'
'Where did Super Bowl 50 take place?'
```

ìš°ë¦¬ëŠ” ê·¸ ëŒ€ë‹µì´ ì‹¤ì œë¡œ ì´ì „ì— ë³¸ ì„¸ ê°€ì§€ ê°€ëŠ¥ì„± ì¤‘ í•˜ë‚˜ì¼ ìˆ˜ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### í•™ìŠµ ë°ì´í„° ì²˜ë¦¬[[processing-the-training-data]]

<Youtube id="qgaM0weJHpA"/>

í›ˆë ¨ ë°ì´í„° ì „ì²˜ë¦¬ë¶€í„° ì‹œì‘í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì–´ë ¤ìš´ ë¶€ë¶„ì€ ì§ˆë¬¸ ë‹µë³€ì— ëŒ€í•œ ë ˆì´ë¸”ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ì»¨í…ìŠ¤íŠ¸ ë‚´ ë‹µë³€ì— í•´ë‹¹í•˜ëŠ” í† í°ì˜ ì‹œì‘ ë° ë ìœ„ì¹˜ê°€ ë©ë‹ˆë‹¤.

í•˜ì§€ë§Œ ë„ˆë¬´ ì•ì„œê°€ì§€ ë§ì. ë¨¼ì € í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ì˜ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” IDë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

```py
from transformers import AutoTokenizer

model_checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
```

ì´ì „ì— ì–¸ê¸‰í–ˆë“¯ì´ BERT ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•  ì˜ˆì •ì´ì§€ë§Œ ë¹ ë¥¸ í† í¬ë‚˜ì´ì €ê°€ êµ¬í˜„ë˜ì–´ ìˆëŠ” í•œ ë‹¤ë¥¸ ëª¨ë¸ ìœ í˜•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [ì´ í° í…Œì´ë¸”](https://huggingface.co/transformers/#supported-frameworks)ì—ì„œ ë¹ ë¥¸ ë²„ì „ê³¼ í•¨ê»˜ ì œê³µë˜ëŠ” ëª¨ë“  ì•„í‚¤í…ì²˜ë¥¼ ë³¼ ìˆ˜ ìˆìœ¼ë©°, ì‚¬ìš© ì¤‘ì¸ `tokenizer` ê°ì²´ê°€ ì‹¤ì œë¡œ ğŸ¤— í† í¬ë‚˜ì´ì €ì˜ ì§€ì›ì„ ë°›ì•„ `is_fast` ì†ì„±ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```py
tokenizer.is_fast
```

```python out
True
```

í† í¬ë‚˜ì´ì €ì— ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì „ë‹¬í•  ìˆ˜ ìˆìœ¼ë©° íŠ¹ìˆ˜ í† í°ì„ ì ì ˆí•˜ê²Œ ì‚½ì…í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì¥ì„ êµ¬ì„±í•©ë‹ˆë‹¤.

```
[CLS] question [SEP] context [SEP]
```

ë‹¤ì‹œ í™•ì¸í•´ ë´…ì‹œë‹¤:

```py
context = raw_datasets["train"][0]["context"]
question = raw_datasets["train"][0]["question"]

inputs = tokenizer(question, context)
tokenizer.decode(inputs["input_ids"])
```

```python out
'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, '
'the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin '
'Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms '
'upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred '
'Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a '
'replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette '
'Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues '
'and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'
```

ê·¸ëŸ° ë‹¤ìŒ ë ˆì´ë¸”ì€ ë‹µë³€ì„ ì‹œì‘í•˜ê³  ëë‚´ëŠ” í† í°ì˜ ì¸ë±ìŠ¤ê°€ ë˜ë©°, ëª¨ë¸ì€ ì…ë ¥ì—ì„œ í† í°ë‹¹ í•˜ë‚˜ì˜ ì‹œì‘ ë° ë ë¡œì§“ì„ ì˜ˆì¸¡í•˜ë„ë¡ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë©° ì´ë¡ ì  ë ˆì´ë¸”ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

<div class="flex justify-center">
<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/qa_labels.svg" alt="One-hot encoded labels for question answering."/>
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/qa_labels-dark.svg" alt="One-hot encoded labels for question answering."/>
</div>

ì´ ê²½ìš° ì»¨í…ìŠ¤íŠ¸ëŠ” ë„ˆë¬´ ê¸¸ì§€ ì•Šì§€ë§Œ ë°ì´í„° ì„¸íŠ¸ì˜ ì¼ë¶€ ì˜ˆì—ëŠ” ìš°ë¦¬ê°€ ì„¤ì •í•œ ìµœëŒ€ ê¸¸ì´(ì´ ê²½ìš° 384)ë¥¼ ì´ˆê³¼í•˜ëŠ” ë§¤ìš° ê¸´ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤. [6ì¥](/course/chapter6/4)ì—ì„œ 'ì§ˆë¬¸-ë‹µë³€' íŒŒì´í”„ë¼ì¸ì˜ ë‚´ë¶€ë¥¼ íƒìƒ‰í–ˆì„ ë•Œ ë³¸ ê²ƒì²˜ëŸ¼ ë°ì´í„° ì„¸íŠ¸ì˜ í•œ ìƒ˜í”Œì—ì„œ ì—¬ëŸ¬ í›ˆë ¨ ê¸°ëŠ¥ì„ ìƒì„±í•˜ì—¬ ê¸´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. ê·¸ ì‚¬ì´ì˜ ìŠ¬ë¼ì´ë”© ì°½.

í˜„ì¬ ì˜ˆì œë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ê²ƒì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ê¸¸ì´ë¥¼ 100ìœ¼ë¡œ ì œí•œí•˜ê³  50ê°œ í† í°ì˜ ìŠ¬ë¼ì´ë”© ì°½ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¸ê³ ë¡œ ìš°ë¦¬ëŠ” ë‹¤ìŒì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

- ìµœëŒ€ ê¸¸ì´ë¥¼ ì„¤ì •í•˜ëŠ” `max_length`(ì—¬ê¸°ì„œëŠ” 100)
- ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ì§ˆë¬¸ì´ ë„ˆë¬´ ê¸´ ê²½ìš° ì»¨í…ìŠ¤íŠ¸(ë‘ ë²ˆì§¸ ìœ„ì¹˜ì— ìˆìŒ)ë¥¼ ìë¥´ë ¤ë©´ `truncation="only_second"`
- ë‘ ê°œì˜ ì—°ì† ì²­í¬ ì‚¬ì´ì— ê²¹ì¹˜ëŠ” í† í° ìˆ˜ë¥¼ ì„¤ì •í•˜ëŠ” `stride`(ì—¬ê¸°ì„œëŠ” 50)
- `return_overflowing_tokens=True` - í† í¬ë‚˜ì´ì €ì—ê²Œ ì˜¤ë²„í”Œë¡œìš° í† í°ì„ ì›í•œë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œë¦½ë‹ˆë‹¤.

```py
inputs = tokenizer(
    question,
    context,
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True,
)

for ids in inputs["input_ids"]:
    print(tokenizer.decode(ids))
```

```python out
'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]'
'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]'
'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]'
'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'
```

ë³´ì‹œë‹¤ì‹œí”¼, ìš°ë¦¬ì˜ ì˜ˆëŠ” 4ê°œì˜ ì…ë ¥ìœ¼ë¡œ ë¶„í• ë˜ì–´ ìˆìœ¼ë©° ê° ì…ë ¥ì—ëŠ” ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ì˜ ì¼ë¶€ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€("Bernadette Soubirous")ì€ ì„¸ ë²ˆì§¸ ë° ë§ˆì§€ë§‰ ì…ë ¥ì—ë§Œ ë‚˜íƒ€ë‚˜ë¯€ë¡œ ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ ê¸´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ëª‡ ê°€ì§€ í›ˆë ¨ ì˜ˆì œë¥¼ ë§Œë“¤ ê²ƒì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ì˜ˆì˜ ê²½ìš° ë¼ë²¨ì€ `start_position = end_position = 0`ì´ ë©ë‹ˆë‹¤(ë”°ë¼ì„œ `[CLS]` í† í°ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤). ë˜í•œ ë¶ˆí–‰í•˜ê²Œë„ ë‹µë³€ì´ ì˜ë ¤ ë‹µë³€ì˜ ì‹œì‘(ë˜ëŠ” ë)ë§Œ ì•Œ ìˆ˜ ìˆë„ë¡ í•´ë‹¹ ë¼ë²¨ì„ ì„¤ì •í•  ê²ƒì…ë‹ˆë‹¤. ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— ì™„ì „íˆ í¬í•¨ëœ ì˜ˆì˜ ê²½ìš° ë¼ë²¨ì€ ë‹µë³€ì´ ì‹œì‘ë˜ëŠ” í† í°ì˜ ì¸ë±ìŠ¤ì™€ ë‹µë³€ì´ ëë‚˜ëŠ” í† í°ì˜ ì¸ë±ìŠ¤ê°€ ë©ë‹ˆë‹¤.

ë°ì´í„°ì„¸íŠ¸ëŠ” ë¬¸ë§¥ ë‚´ ë‹µë³€ì˜ ì‹œì‘ ë¬¸ìë¥¼ ì œê³µí•˜ë©°, ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ì¶”ê°€í•˜ì—¬ ë¬¸ë§¥ ë‚´ ë ë¬¸ìë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í† í° ì¸ë±ìŠ¤ì— ë§¤í•‘í•˜ë ¤ë©´ [6ì¥](/course/chapter6/4)ì—ì„œ ì—°êµ¬í•œ ì˜¤í”„ì…‹ ë§¤í•‘ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. `return_offsets_mapping=True`ë¥¼ ì „ë‹¬í•˜ì—¬ í† í¬ë‚˜ì´ì €ê°€ ì´ë¥¼ ë°˜í™˜í•˜ë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
inputs = tokenizer(
    question,
    context,
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True,
    return_offsets_mapping=True,
)
inputs.keys()
```

```python out
dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])
```

ë³´ì‹œë‹¤ì‹œí”¼, ìš°ë¦¬ëŠ” ì¼ë°˜ì ì¸ ì…ë ¥ ID, í† í° ìœ í˜• ID ë° ì£¼ì˜ ë§ˆìŠ¤í¬ëŠ” ë¬¼ë¡  í•„ìš”í•œ ì˜¤í”„ì…‹ ë§¤í•‘ê³¼ ì¶”ê°€ í‚¤ `overflow_to_sample_mapping`ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. í•´ë‹¹ ê°’ì€ ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë™ì‹œì— í† í°í™”í•  ë•Œ ìœ ìš©í•  ê²ƒì…ë‹ˆë‹¤(í† í°ë‚˜ì´ì €ê°€ Rustì˜ ì§€ì›ì„ ë°›ëŠ”ë‹¤ëŠ” ì‚¬ì‹¤ì„ í™œìš©í•˜ë ¤ë©´ ì´ë ‡ê²Œ í•´ì•¼ í•©ë‹ˆë‹¤). í•˜ë‚˜ì˜ ìƒ˜í”Œì´ ì—¬ëŸ¬ ê¸°ëŠ¥ì„ ì œê³µí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê° ê¸°ëŠ¥ì„ ì›ë˜ ì˜ˆì œì— ë§¤í•‘í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” í•˜ë‚˜ì˜ ì˜ˆì‹œë§Œ í† í°í™”í–ˆê¸° ë•Œë¬¸ì— '0' ëª©ë¡ì„ ì–»ìŠµë‹ˆë‹¤.

```py
inputs["overflow_to_sample_mapping"]
```

```python out
[0, 0, 0, 0]
```

ê·¸ëŸ¬ë‚˜ ë” ë§ì€ ì˜ˆì‹œë¥¼ í† í°í™”í•˜ë©´ ì´ëŠ” ë”ìš± ìœ ìš©í•´ì§ˆ ê²ƒì…ë‹ˆë‹¤.

```py
inputs = tokenizer(
    raw_datasets["train"][2:6]["question"],
    raw_datasets["train"][2:6]["context"],
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True,
    return_offsets_mapping=True,
)

print(f"The 4 examples gave {len(inputs['input_ids'])} features.")
print(f"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.")
```

```python out
'The 4 examples gave 19 features.'
'Here is where each comes from: [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3].'
```

ë³´ì‹œë‹¤ì‹œí”¼, ì²˜ìŒ ì„¸ ê°€ì§€ ì˜ˆ(í›ˆë ¨ ì„¸íŠ¸ì˜ ì¸ë±ìŠ¤ 2, 3, 4)ëŠ” ê°ê° 4ê°œì˜ íŠ¹ì„±ì„ ì œê³µí•˜ê³  ë§ˆì§€ë§‰ ì˜ˆ(í›ˆë ¨ ì„¸íŠ¸ì˜ ì¸ë±ìŠ¤ 5)ëŠ” 7ê°œì˜ íŠ¹ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.

ì´ ì •ë³´ëŠ” ìš°ë¦¬ê°€ ì–»ì€ ê° ê¸°ëŠ¥ì„ í•´ë‹¹ ë ˆì´ë¸”ì— ë§¤í•‘í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤. ì•ì„œ ì–¸ê¸‰í–ˆë“¯ì´ í•´ë‹¹ ë¼ë²¨ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

- ì‘ë‹µì´ ì»¨í…ìŠ¤íŠ¸ì˜ í•´ë‹¹ ë²”ìœ„ì— ì—†ëŠ” ê²½ìš° `(0, 0)`
- ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì˜ í•´ë‹¹ ë²”ìœ„ì— ìˆëŠ” ê²½ìš° `(start_position, end_position)`, `start_position`ì€ ë‹µë³€ ì‹œì‘ ì‹œ í† í°ì˜ ì¸ë±ìŠ¤(ì…ë ¥ IDì—ì„œ)ì´ê³  `end_position`ì€ ë‹µë³€ì´ ëë‚˜ëŠ” í† í°(ì…ë ¥ IDì— ìˆìŒ)

ì´ë“¤ ì¤‘ ì–´ë–¤ ê²½ìš°ì¸ì§€, ê·¸ë¦¬ê³  í•´ë‹¹ë˜ëŠ” ê²½ìš° í† í°ì˜ ìœ„ì¹˜ë¥¼ ê²°ì •í•˜ê¸° ìœ„í•´ ë¨¼ì € ì…ë ¥ IDì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‹œì‘í•˜ê³  ëë‚´ëŠ” ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ í† í° ìœ í˜• IDë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ ëª¨ë“  ëª¨ë¸ì— ë°˜ë“œì‹œ ì¡´ì¬í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆë¯€ë¡œ(ì˜ˆë¥¼ ë“¤ì–´ DistilBERTì—ì„œëŠ” ì´ë¥¼ ìš”êµ¬í•˜ì§€ ì•ŠìŒ) ëŒ€ì‹  `BatchEncoding`ì˜ `sequence_ids()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í† í¬ë‚˜ì´ì €ê°€ ë°˜í™˜ë©ë‹ˆë‹¤.

í† í° ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ ì›ë˜ ì»¨í…ìŠ¤íŠ¸ ë‚´ì˜ ë¬¸ì ë²”ìœ„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë‘ ì •ìˆ˜ì˜ íŠœí”Œì¸ í•´ë‹¹ ì˜¤í”„ì…‹ì„ ì‚´í´ë´…ë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ì´ ê¸°ëŠ¥ì˜ ì»¨í…ìŠ¤íŠ¸ ë©ì–´ë¦¬ê°€ ë‹µë³€ ì´í›„ì— ì‹œì‘í•˜ëŠ”ì§€ ì•„ë‹ˆë©´ ë‹µë³€ì´ ì‹œì‘ë˜ê¸° ì „ì— ëë‚˜ëŠ”ì§€ ê°ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì´ ê²½ìš° ë¼ë²¨ì€ '(0, 0)'ì…ë‹ˆë‹¤). ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° ë£¨í”„ë¥¼ í†µí•´ ë‹µë³€ì˜ ì²« ë²ˆì§¸ í† í°ê³¼ ë§ˆì§€ë§‰ í† í°ì„ ì°¾ìŠµë‹ˆë‹¤.

```py
answers = raw_datasets["train"][2:6]["answers"]
start_positions = []
end_positions = []

for i, offset in enumerate(inputs["offset_mapping"]):
    sample_idx = inputs["overflow_to_sample_mapping"][i]
    answer = answers[sample_idx]
    start_char = answer["answer_start"][0]
    end_char = answer["answer_start"][0] + len(answer["text"][0])
    sequence_ids = inputs.sequence_ids(i)

    # Find the start and end of the context
    idx = 0
    while sequence_ids[idx] != 1:
        idx += 1
    context_start = idx
    while sequence_ids[idx] == 1:
        idx += 1
    context_end = idx - 1

    # If the answer is not fully inside the context, label is (0, 0)
    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:
        start_positions.append(0)
        end_positions.append(0)
    else:
        # Otherwise it's the start and end token positions
        idx = context_start
        while idx <= context_end and offset[idx][0] <= start_char:
            idx += 1
        start_positions.append(idx - 1)

        idx = context_end
        while idx >= context_start and offset[idx][1] >= end_char:
            idx -= 1
        end_positions.append(idx + 1)

start_positions, end_positions
```

```python out
([83, 51, 19, 0, 0, 64, 27, 0, 34, 0, 0, 0, 67, 34, 0, 0, 0, 0, 0],
 [85, 53, 21, 0, 0, 70, 33, 0, 40, 0, 0, 0, 68, 35, 0, 0, 0, 0, 0])
```

ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ëª‡ ê°€ì§€ ê²°ê³¼ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ê¸°ëŠ¥ì˜ ê²½ìš° `(83, 85)`ë¥¼ ë ˆì´ë¸”ë¡œ ì°¾ìœ¼ë¯€ë¡œ ì´ë¡ ì  ë‹µë³€ì„ 83ì—ì„œ 85(í¬í•¨)ê¹Œì§€ ë””ì½”ë”©ëœ í† í° ë²”ìœ„ì™€ ë¹„êµí•´ ë³´ê² ìŠµë‹ˆë‹¤.

```py
idx = 0
sample_idx = inputs["overflow_to_sample_mapping"][idx]
answer = answers[sample_idx]["text"][0]

start = start_positions[idx]
end = end_positions[idx]
labeled_answer = tokenizer.decode(inputs["input_ids"][idx][start : end + 1])

print(f"Theoretical answer: {answer}, labels give: {labeled_answer}")
```

```python out
'Theoretical answer: the Main Building, labels give: the Main Building'
```

ê·¸ë˜ì„œ ê·¸ê²ƒì€ ì¼ì¹˜ì…ë‹ˆë‹¤! ì´ì œ ì¸ë±ìŠ¤ 4ë¥¼ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ë ˆì´ë¸”ì„ '(0, 0)'ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‹µë³€ì´ í•´ë‹¹ ê¸°ëŠ¥ì˜ ì»¨í…ìŠ¤íŠ¸ ì²­í¬ì— ì—†ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

```py
idx = 4
sample_idx = inputs["overflow_to_sample_mapping"][idx]
answer = answers[sample_idx]["text"][0]

decoded_example = tokenizer.decode(inputs["input_ids"][idx])
print(f"Theoretical answer: {answer}, decoded example: {decoded_example}")
```

```python out
'Theoretical answer: a Marian place of prayer and reflection, decoded example: [CLS] What is the Grotto at Notre Dame? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grot [SEP]'
```

ì‹¤ì œë¡œ ìš°ë¦¬ëŠ” ì»¨í…ìŠ¤íŠ¸ ë‚´ë¶€ì—ì„œ ë‹µì„ ë³¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

<Tip>

âœï¸ **ë‹¹ì‹  ì°¨ë¡€!** XLNet ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•  ë•Œ ì™¼ìª½ì— íŒ¨ë”©ì´ ì ìš©ë˜ê³  ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ê°€ ì „í™˜ë©ë‹ˆë‹¤. ë°©ê¸ˆ ë³¸ ëª¨ë“  ì½”ë“œë¥¼ XLNet ì•„í‚¤í…ì²˜ì— ì ìš©í•˜ê³  `padding=True`ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. íŒ¨ë”©ì´ ì ìš©ëœ ê²½ìš° `[CLS]` í† í°ì´ 0 ìœ„ì¹˜ì— ìˆì§€ ì•Šì„ ìˆ˜ ìˆë‹¤ëŠ” ì ì— ìœ ì˜í•˜ì„¸ìš”.
</Tip>

ì´ì œ í•™ìŠµ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì‚´í´ë³´ì•˜ìœ¼ë¯€ë¡œ ì´ë¥¼ ì „ì²´ í•™ìŠµ ë°ì´í„° ì„¸íŠ¸ì— ì ìš©í•  í•¨ìˆ˜ë¡œ ê·¸ë£¹í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ì»¨í…ìŠ¤íŠ¸ëŠ” ê¸¸ê¸° ë•Œë¬¸ì—(í•´ë‹¹ ìƒ˜í”Œì€ ì—¬ëŸ¬ ê¸°ëŠ¥ìœ¼ë¡œ ë¶„í• ë˜ë¯€ë¡œ) ëª¨ë“  ê¸°ëŠ¥ì„ ì„¤ì •í•œ ìµœëŒ€ ê¸¸ì´ë¡œ ì±„ìš¸ ê²ƒì´ë¯€ë¡œ ì—¬ê¸°ì— ë™ì  íŒ¨ë”©ì„ ì ìš©í•´ë„ ì‹¤ì§ˆì ì¸ ì´ì ì€ ì—†ìŠµë‹ˆë‹¤.

```py
max_length = 384
stride = 128


def preprocess_training_examples(examples):
    questions = [q.strip() for q in examples["question"]]
    inputs = tokenizer(
        questions,
        examples["context"],
        max_length=max_length,
        truncation="only_second",
        stride=stride,
        return_overflowing_tokens=True,
        return_offsets_mapping=True,
        padding="max_length",
    )

    offset_mapping = inputs.pop("offset_mapping")
    sample_map = inputs.pop("overflow_to_sample_mapping")
    answers = examples["answers"]
    start_positions = []
    end_positions = []

    for i, offset in enumerate(offset_mapping):
        sample_idx = sample_map[i]
        answer = answers[sample_idx]
        start_char = answer["answer_start"][0]
        end_char = answer["answer_start"][0] + len(answer["text"][0])
        sequence_ids = inputs.sequence_ids(i)

        # Find the start and end of the context
        idx = 0
        while sequence_ids[idx] != 1:
            idx += 1
        context_start = idx
        while sequence_ids[idx] == 1:
            idx += 1
        context_end = idx - 1

        # If the answer is not fully inside the context, label is (0, 0)
        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:
            start_positions.append(0)
            end_positions.append(0)
        else:
            # Otherwise it's the start and end token positions
            idx = context_start
            while idx <= context_end and offset[idx][0] <= start_char:
                idx += 1
            start_positions.append(idx - 1)

            idx = context_end
            while idx >= context_start and offset[idx][1] >= end_char:
                idx -= 1
            end_positions.append(idx + 1)

    inputs["start_positions"] = start_positions
    inputs["end_positions"] = end_positions
    return inputs
```

ì‚¬ìš©ë˜ëŠ” ìµœëŒ€ ê¸¸ì´ì™€ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ì˜ ê¸¸ì´ë¥¼ ê²°ì •í•˜ê¸° ìœ„í•´ ë‘ ê°œì˜ ìƒìˆ˜ë¥¼ ì •ì˜í–ˆìœ¼ë©° í† í°í™”í•˜ê¸° ì „ì— ì•½ê°„ì˜ ì •ë¦¬ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. SQuAD ë°ì´í„° ì„¸íŠ¸ì˜ ì¼ë¶€ ì§ˆë¬¸ì—ëŠ” ì‹œì‘ ë¶€ë¶„ê³¼ ë ë¶€ë¶„ì— ì¶”ê°€ ê³µë°±ì´ ìˆìŠµë‹ˆë‹¤. ì•„ë¬´ê²ƒë„ ì¶”ê°€í•˜ì§€ ì•Šê³ (RoBERTaì™€ ê°™ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° í† í°í™”í•  ë•Œ ê³µê°„ì„ ì°¨ì§€í•˜ë¯€ë¡œ) ì¶”ê°€ ê³µê°„ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.

ì´ í•¨ìˆ˜ë¥¼ ì „ì²´ í›ˆë ¨ ì„¸íŠ¸ì— ì ìš©í•˜ê¸° ìœ„í•´ `batched=True` í”Œë˜ê·¸ì™€ í•¨ê»˜ `Dataset.map()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë°ì´í„° ì„¸íŠ¸ì˜ ê¸¸ì´ë¥¼ ë³€ê²½í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” í•„ìš”í•©ë‹ˆë‹¤(í•˜ë‚˜ì˜ ì˜ˆê°€ ì—¬ëŸ¬ í›ˆë ¨ ê¸°ëŠ¥ì„ ì œê³µí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ).

```py
train_dataset = raw_datasets["train"].map(
    preprocess_training_examples,
    batched=True,
    remove_columns=raw_datasets["train"].column_names,
)
len(raw_datasets["train"]), len(train_dataset)
```

```python out
(87599, 88729)
```

ë³´ì‹œë‹¤ì‹œí”¼ ì „ì²˜ë¦¬ë¥¼ í†µí•´ ëŒ€ëµ 1,000ê°œì˜ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ í›ˆë ¨ ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€ì¦ ì„¸íŠ¸ì˜ ì „ì²˜ë¦¬ë¥¼ ìì„¸íˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤!

### ê²€ì¦ ë°ì´í„° ì²˜ë¦¬[[processing-the-validation-data]]

ê²€ì¦ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” ê²ƒì€ ë ˆì´ë¸”ì„ ìƒì„±í•  í•„ìš”ê°€ ì—†ê¸° ë•Œë¬¸ì— ì•½ê°„ ë” ì‰¬ìš¸ ê²ƒì…ë‹ˆë‹¤(ê²€ì¦ ì†ì‹¤ì„ ê³„ì‚°í•˜ê³  ì‹¶ì§€ ì•Šì€ í•œ, ê·¸ ìˆ«ìëŠ” ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì¢‹ì€ì§€ ì´í•´í•˜ëŠ” ë° ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤). ì§„ì •í•œ ì¦ê±°ì›€ì€ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ì›ë˜ ë§¥ë½ì˜ ë²”ìœ„ë¡œ í•´ì„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì˜¤í”„ì…‹ ë§¤í•‘ê³¼ ìƒì„±ëœ ê° ê¸°ëŠ¥ì„ ì›ë³¸ ì˜ˆì œì™€ ì¼ì¹˜ì‹œí‚¤ëŠ” ë°©ë²•ì„ ëª¨ë‘ ì €ì¥í•˜ë©´ ë©ë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ì„¸íŠ¸ì— ID ì—´ì´ ìˆìœ¼ë¯€ë¡œ í•´ë‹¹ IDë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.

ì—¬ê¸°ì— ì¶”ê°€í•  ìœ ì¼í•œ ê²ƒì€ ì˜¤í”„ì…‹ ë§¤í•‘ì„ ì•½ê°„ ì •ë¦¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì˜¤í”„ì…‹ì´ í¬í•¨ë˜ì§€ë§Œ ì¼ë‹¨ ì‚¬í›„ ì²˜ë¦¬ ë‹¨ê³„ì— ë“¤ì–´ê°€ë©´ ì…ë ¥ IDì˜ ì–´ëŠ ë¶€ë¶„ì´ ì»¨í…ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ê³  ì–´ëŠ ë¶€ë¶„ì´ ì§ˆë¬¸ì¸ì§€ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤(` ìš°ë¦¬ê°€ ì‚¬ìš©í•œ ì‹œí€€ìŠ¤_ids()` ë©”ì„œë“œëŠ” í† í¬ë‚˜ì´ì €ì˜ ì¶œë ¥ì—ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ì˜¤í”„ì…‹ì„ `None`ìœ¼ë¡œ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤.

```py
def preprocess_validation_examples(examples):
    questions = [q.strip() for q in examples["question"]]
    inputs = tokenizer(
        questions,
        examples["context"],
        max_length=max_length,
        truncation="only_second",
        stride=stride,
        return_overflowing_tokens=True,
        return_offsets_mapping=True,
        padding="max_length",
    )

    sample_map = inputs.pop("overflow_to_sample_mapping")
    example_ids = []

    for i in range(len(inputs["input_ids"])):
        sample_idx = sample_map[i]
        example_ids.append(examples["id"][sample_idx])

        sequence_ids = inputs.sequence_ids(i)
        offset = inputs["offset_mapping"][i]
        inputs["offset_mapping"][i] = [
            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)
        ]

    inputs["example_id"] = example_ids
    return inputs
```

ì´ì „ê³¼ ê°™ì´ ì „ì²´ ê²€ì¦ ë°ì´í„°ì„¸íŠ¸ì— ì´ í•¨ìˆ˜ë¥¼ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
validation_dataset = raw_datasets["validation"].map(
    preprocess_validation_examples,
    batched=True,
    remove_columns=raw_datasets["validation"].column_names,
)
len(raw_datasets["validation"]), len(validation_dataset)
```

```python out
(10570, 10822)
```

ì´ ê²½ìš°ì—ëŠ” ëª‡ ë°± ê°œì˜ ìƒ˜í”Œë§Œ ì¶”ê°€í–ˆê¸° ë•Œë¬¸ì— ê²€ì¦ ë°ì´í„° ì„¸íŠ¸ì˜ ì»¨í…ìŠ¤íŠ¸ê°€ ì•½ê°„ ë” ì§§ì€ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.

ì´ì œ ëª¨ë“  ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ í›ˆë ¨ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

{#if fw === 'pt'}

## `Trainer` APIë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •[[fine-tuning-the-model-with-the-trainer-api]]

ì´ ì˜ˆì œì˜ í•™ìŠµ ì½”ë“œëŠ” ì´ì „ ì„¹ì…˜ì˜ ì½”ë“œì™€ ë§¤ìš° ë¹„ìŠ·í•´ ë³´ì…ë‹ˆë‹¤. ê°€ì¥ ì–´ë ¤ìš´ ì ì€ `compute_metrics()` í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì„¤ì •í•œ ìµœëŒ€ ê¸¸ì´ê¹Œì§€ ëª¨ë“  ìƒ˜í”Œì„ ì±„ì› ê¸° ë•Œë¬¸ì— ì •ì˜í•  ë°ì´í„° ì½œë ˆì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ì´ ë©”íŠ¸ë¦­ ê³„ì‚°ì€ ì‹¤ì œë¡œ ìš°ë¦¬ê°€ ê±±ì •í•´ì•¼ í•  ìœ ì¼í•œ ê²ƒì…ë‹ˆë‹¤. ì–´ë ¤ìš´ ë¶€ë¶„ì€ ëª¨ë¸ ì˜ˆì¸¡ì„ ì›ë³¸ ì˜ˆì œì˜ í…ìŠ¤íŠ¸ ë²”ìœ„ë¡œ í›„ì²˜ë¦¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë©´ ğŸ¤— ë°ì´í„° ì„¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì¸¡ì •í•­ëª©ì´ ëŒ€ë¶€ë¶„ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

{:else}

## Kerasë¡œ ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •[[fine-tuning-the-model-with-keras]]

ì´ ì˜ˆì œì˜ í•™ìŠµ ì½”ë“œëŠ” ì´ì „ ì„¹ì…˜ì˜ ì½”ë“œì™€ ë§¤ìš° ë¹„ìŠ·í•´ ë³´ì´ì§€ë§Œ ì¸¡ì •í•­ëª©ì„ ê³„ì‚°í•˜ëŠ” ê²ƒì€ ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤. ìš°ë¦¬ê°€ ì„¤ì •í•œ ìµœëŒ€ ê¸¸ì´ê¹Œì§€ ëª¨ë“  ìƒ˜í”Œì„ ì±„ì› ê¸° ë•Œë¬¸ì— ì •ì˜í•  ë°ì´í„° ì½œë ˆì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ì´ ë©”íŠ¸ë¦­ ê³„ì‚°ì€ ì‹¤ì œë¡œ ìš°ë¦¬ê°€ ê±±ì •í•´ì•¼ í•  ìœ ì¼í•œ ê²ƒì…ë‹ˆë‹¤. ì–´ë ¤ìš´ ë¶€ë¶„ì€ ëª¨ë¸ ì˜ˆì¸¡ì„ ì›ë³¸ ì˜ˆì œì˜ í…ìŠ¤íŠ¸ ë²”ìœ„ë¡œ í›„ì²˜ë¦¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë©´ ğŸ¤— ë°ì´í„° ì„¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì¸¡ì •í•­ëª©ì´ ëŒ€ë¶€ë¶„ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

{/if}

### í›„ì²˜ë¦¬[[post-processing]]

{#if fw === 'pt'}

<Youtube id="BNy08iIWVJM"/>

{:else}

<Youtube id="VN67ZpN33Ss"/>

{/if}

ëª¨ë¸ì€ [`ì§ˆë¬¸-ë‹µë³€` íŒŒì´í”„ë¼ì¸](/course/chapter6/3b)ì„ íƒìƒ‰í•˜ëŠ” ë™ì•ˆ ë³¸ ê²ƒì²˜ëŸ¼ ì…ë ¥ IDì—ì„œ ë‹µë³€ì˜ ì‹œì‘ ë° ë ìœ„ì¹˜ì— ëŒ€í•œ ë¡œì§“ì„ ì¶œë ¥í•©ë‹ˆë‹¤. ì‚¬í›„ ì²˜ë¦¬ ë‹¨ê³„ëŠ” ìš°ë¦¬ê°€ ìˆ˜í–‰í•œ ì‘ì—…ê³¼ ìœ ì‚¬í•˜ë¯€ë¡œ ë‹¤ìŒì€ ìš°ë¦¬ê°€ ìˆ˜í–‰í•œ ì‘ì—…ì„ ê°„ëµíˆ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.

- ì»¨í…ìŠ¤íŠ¸ ì™¸ë¶€ì˜ í† í°ì— í•´ë‹¹í•˜ëŠ” ì‹œì‘ ë° ì¢…ë£Œ ë¡œì§“ì„ ë§ˆìŠ¤í‚¹í–ˆìŠµë‹ˆë‹¤.
- ê·¸ëŸ° ë‹¤ìŒ ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œì‘ ë° ì¢…ë£Œ ë¡œì§“ì„ í™•ë¥ ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.
- í•´ë‹¹ ë‘ í™•ë¥ ì˜ ê³±ì„ ì·¨í•˜ì—¬ ê° '(start_token, end_token)' ìŒì— ì ìˆ˜ë¥¼ ë¶€ì—¬í–ˆìŠµë‹ˆë‹¤.
- ìœ íš¨í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ìµœëŒ€ ì ìˆ˜ë¥¼ ê°€ì§„ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤(ì˜ˆ: 'end_token'ë³´ë‹¤ ë‚®ì€ 'start_token').

ì—¬ê¸°ì„œëŠ” ì‹¤ì œ ì ìˆ˜ë¥¼ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ê¸° ë•Œë¬¸ì—(ì˜ˆìƒ ë‹µë³€ë§Œ) ì´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì•½ê°„ ë³€ê²½í•˜ê² ìŠµë‹ˆë‹¤. ì´ëŠ” ì†Œí”„íŠ¸ë§¥ìŠ¤ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë” ë¹ ë¥´ê²Œ ì§„í–‰í•˜ê¸° ìœ„í•´ ê°€ëŠ¥í•œ ëª¨ë“  `(start_token, end_token)` ìŒì˜ ì ìˆ˜ë¥¼ ë§¤ê¸°ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ê°€ì¥ ë†’ì€ `n_best` ë¡œì§“(`n_best=20` ì‚¬ìš©)ì— í•´ë‹¹í•˜ëŠ” ìŒë§Œ ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤. ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ ê±´ë„ˆë›¸ ê²ƒì´ë¯€ë¡œ í•´ë‹¹ ì ìˆ˜ëŠ” ë¡œì§“ ì ìˆ˜ê°€ ë˜ë©° \\(\log(ab) = \log( ê·œì¹™ ë•Œë¬¸ì— ê³± ëŒ€ì‹ ì— ì‹œì‘ ë° ë ë¡œì§“ì˜ í•©ì„ ì·¨í•˜ì—¬ ì–»ìŠµë‹ˆë‹¤. a) + \log(b)\\)).

ì´ ëª¨ë“  ê²ƒì„ ì…ì¦í•˜ë ¤ë©´ ì¼ì¢…ì˜ ì˜ˆì¸¡ì´ í•„ìš”í•©ë‹ˆë‹¤. ì•„ì§ ëª¨ë¸ì„ í›ˆë ¨í•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ QA íŒŒì´í”„ë¼ì¸ì˜ ê¸°ë³¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê²€ì¦ ì„¸íŠ¸ì˜ ì‘ì€ ë¶€ë¶„ì— ëŒ€í•œ ì¼ë¶€ ì˜ˆì¸¡ì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤. ì´ì „ê³¼ ë™ì¼í•œ ì²˜ë¦¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ì—­ ìƒìˆ˜ `tokenizer`ì— ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì— í•´ë‹¹ ê°ì²´ë¥¼ ì„ì‹œë¡œ ì‚¬ìš©í•˜ë ¤ëŠ” ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì €ë¡œ ë³€ê²½í•˜ë©´ ë©ë‹ˆë‹¤.

```python
small_eval_set = raw_datasets["validation"].select(range(100))
trained_checkpoint = "distilbert-base-cased-distilled-squad"

tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)
eval_set = small_eval_set.map(
    preprocess_validation_examples,
    batched=True,
    remove_columns=raw_datasets["validation"].column_names,
)
```

ì´ì œ ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ í† í¬ë‚˜ì´ì €ë¥¼ ì›ë˜ ì„ íƒí•œ ê²ƒìœ¼ë¡œ ë‹¤ì‹œ ë³€ê²½í•©ë‹ˆë‹¤.

```python
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
```

ê·¸ëŸ° ë‹¤ìŒ ëª¨ë¸ì—ì„œ ì˜ˆìƒí•˜ì§€ ì•Šì€ 'eval_set' ì—´ì„ ì œê±°í•˜ê³  ì‘ì€ ê²€ì¦ ì„¸íŠ¸ê°€ ëª¨ë‘ í¬í•¨ëœ ë°°ì¹˜ë¥¼ êµ¬ì¶•í•œ í›„ ëª¨ë¸ì„ í†µí•´ ì „ë‹¬í•©ë‹ˆë‹¤. GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²½ìš° ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ë¹ ë¥´ê²Œ ì§„í–‰í•©ë‹ˆë‹¤.

{#if fw === 'pt'}

```python
import torch
from transformers import AutoModelForQuestionAnswering

eval_set_for_model = eval_set.remove_columns(["example_id", "offset_mapping"])
eval_set_for_model.set_format("torch")

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}
trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(
    device
)

with torch.no_grad():
    outputs = trained_model(**batch)
```

`Trainer`ëŠ” NumPy ë°°ì—´ë¡œ ì˜ˆì¸¡ì„ ì œê³µí•˜ë¯€ë¡œ ì‹œì‘ ë° ë ë¡œì§“ì„ ê°€ì ¸ì™€ í•´ë‹¹ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```python
start_logits = outputs.start_logits.cpu().numpy()
end_logits = outputs.end_logits.cpu().numpy()
```

{:else}

```python
import tensorflow as tf
from transformers import TFAutoModelForQuestionAnswering

eval_set_for_model = eval_set.remove_columns(["example_id", "offset_mapping"])
eval_set_for_model.set_format("numpy")

batch = {k: eval_set_for_model[k] for k in eval_set_for_model.column_names}
trained_model = TFAutoModelForQuestionAnswering.from_pretrained(trained_checkpoint)

outputs = trained_model(**batch)
```

ì‹¤í—˜ì˜ í¸ì˜ë¥¼ ìœ„í•´ ì´ëŸ¬í•œ ì¶œë ¥ì„ NumPy ë°°ì—´ë¡œ ë³€í™˜í•˜ê² ìŠµë‹ˆë‹¤.

```python
start_logits = outputs.start_logits.numpy()
end_logits = outputs.end_logits.numpy()
```

{/if}

ì´ì œ `small_eval_set`ì—ì„œ ê° ì˜ˆì‹œì— ëŒ€í•œ ì˜ˆì¸¡ ë‹µì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤. í•˜ë‚˜ì˜ ì˜ˆê°€ `eval_set`ì—ì„œ ì—¬ëŸ¬ ê¸°ëŠ¥ìœ¼ë¡œ ë¶„í• ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” `small_eval_set`ì˜ ê° ì˜ˆë¥¼ `eval_set`ì˜ í•´ë‹¹ ê¸°ëŠ¥ì— ë§¤í•‘í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

```python
import collections

example_to_features = collections.defaultdict(list)
for idx, feature in enumerate(eval_set):
    example_to_features[feature["example_id"]].append(idx)
```

ì´ë¥¼ í†µí•´ ìš°ë¦¬ëŠ” ëª¨ë“  ì˜ˆì œë¥¼ ë°˜ë³µí•˜ê³  ê° ì˜ˆì œì— ëŒ€í•´ ê´€ë ¨ëœ ëª¨ë“  ê¸°ëŠ¥ì„ í†µí•´ ì‹¤ì œë¡œ ì‘ì—…ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì „ì— ë§í–ˆë“¯ì´ ë‹¤ìŒì„ ì œê³µí•˜ëŠ” ìœ„ì¹˜ë¥¼ ì œì™¸í•˜ê³  'n_best' ì‹œì‘ ë¡œì§“ê³¼ ë ë¡œì§“ì— ëŒ€í•œ ë¡œì§“ ì ìˆ˜ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

- ë¬¸ë§¥ì— ë§ì§€ ì•ŠëŠ” ë‹µë³€
- ìŒìˆ˜ ê¸¸ì´ì˜ ë‹µë³€
- ë‹µë³€ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤(`max_answer_length=30`ì—ì„œ ê°€ëŠ¥ì„±ì„ ì œí•œí•©ë‹ˆë‹¤).

í•œ ê°€ì§€ ì˜ˆì— ëŒ€í•´ ì ìˆ˜ê°€ ë§¤ê²¨ì§„ ê°€ëŠ¥í•œ ë‹µë³€ì„ ëª¨ë‘ ì–»ì€ í›„ì—ëŠ” ê°€ì¥ ì¢‹ì€ ë¡œì§“ ì ìˆ˜ë¥¼ ê°€ì§„ ë‹µë³€ì„ ì„ íƒí•©ë‹ˆë‹¤.

```python
import numpy as np

n_best = 20
max_answer_length = 30
predicted_answers = []

for example in small_eval_set:
    example_id = example["id"]
    context = example["context"]
    answers = []

    for feature_index in example_to_features[example_id]:
        start_logit = start_logits[feature_index]
        end_logit = end_logits[feature_index]
        offsets = eval_set["offset_mapping"][feature_index]

        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()
        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()
        for start_index in start_indexes:
            for end_index in end_indexes:
                # Skip answers that are not fully in the context
                if offsets[start_index] is None or offsets[end_index] is None:
                    continue
                # Skip answers with a length that is either < 0 or > max_answer_length.
                if (
                    end_index < start_index
                    or end_index - start_index + 1 > max_answer_length
                ):
                    continue

                answers.append(
                    {
                        "text": context[offsets[start_index][0] : offsets[end_index][1]],
                        "logit_score": start_logit[start_index] + end_logit[end_index],
                    }
                )

    best_answer = max(answers, key=lambda x: x["logit_score"])
    predicted_answers.append({"id": example_id, "prediction_text": best_answer["text"]})
```

ì˜ˆì¸¡ ë‹µë³€ì˜ ìµœì¢… í˜•ì‹ì€ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ì¸¡ì •í•­ëª©ì—ì„œ ì˜ˆìƒë˜ëŠ” í˜•ì‹ì…ë‹ˆë‹¤. í‰ì†Œì™€ ë§ˆì°¬ê°€ì§€ë¡œ ğŸ¤— Evaluate ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
import evaluate

metric = evaluate.load("squad")
```

ì´ ì¸¡ì •í•­ëª©ì€ ìœ„ì—ì„œ ë³¸ í˜•ì‹(ì˜ˆì œ IDì— ëŒ€í•´ í•˜ë‚˜ì˜ í‚¤ì™€ ì˜ˆì¸¡ í…ìŠ¤íŠ¸ì— ëŒ€í•´ í•˜ë‚˜ì˜ í‚¤ê°€ ìˆëŠ” ì‚¬ì „ ëª©ë¡)ì˜ ì˜ˆì¸¡ ë‹µë³€ê³¼ ì•„ë˜ í˜•ì‹(í•˜ë‚˜ì˜ í‚¤ê°€ ìˆëŠ” ì‚¬ì „ ëª©ë¡)ì˜ ì´ë¡ ì  ë‹µë³€ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤. ì˜ˆì œì˜ ID ë° ê°€ëŠ¥í•œ ë‹µë³€ì— ëŒ€í•œ í‚¤ í•˜ë‚˜):

```python
theoretical_answers = [
    {"id": ex["id"], "answers": ex["answers"]} for ex in small_eval_set
]
```

ì´ì œ ë‘ ëª©ë¡ì˜ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì‚´í´ë´„ìœ¼ë¡œì¨ í•©ë¦¬ì ì¸ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
print(predicted_answers[0])
print(theoretical_answers[0])
```

```python out
{'id': '56be4db0acb8001400a502ec', 'prediction_text': 'Denver Broncos'}
{'id': '56be4db0acb8001400a502ec', 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}}
```

ë‚˜ì˜ì§€ ì•Šì•„! ì´ì œ ì¸¡ì •í•­ëª©ì´ ì œê³µí•˜ëŠ” ì ìˆ˜ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

```python
metric.compute(predictions=predicted_answers, references=theoretical_answers)
```

```python out
{'exact_match': 83.0, 'f1': 88.25}
```


1,220 / 5,000
ë‹¤ì‹œ ë§í•˜ì§€ë§Œ, [í•´ë‹¹ ë…¼ë¬¸](https://arxiv.org/abs/1910.01108v2)ì— ë”°ë¥´ë©´ SQuADì—ì„œ ë¯¸ì„¸ ì¡°ì •ëœ DistilBERTê°€ ì „ì²´ ë°ì´í„°ì„¸íŠ¸ì—ì„œ í•´ë‹¹ ì ìˆ˜ì— ëŒ€í•´ 79.1ê³¼ 86.9ë¥¼ ì–»ëŠ”ë‹¤ëŠ” ì ì„ ê³ ë ¤í•˜ë©´ ë‹¤ì†Œ ì¢‹ìŠµë‹ˆë‹¤.
{#if fw === 'pt'}

ì´ì œ ë°©ê¸ˆ ìˆ˜í–‰í•œ ëª¨ë“  ì‘ì—…ì„ `Trainer`ì—ì„œ ì‚¬ìš©í•  `compute_metrics()` í•¨ìˆ˜ì— ë„£ì–´ ë³´ê² ìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ `compute_metrics()` í•¨ìˆ˜ëŠ” ë¡œì§€íŠ¸ì™€ ë¼ë²¨ì´ í¬í•¨ëœ `eval_preds` íŠœí”Œë§Œ ë°›ìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œëŠ” ì˜¤í”„ì…‹ì— ëŒ€í•œ ê¸°ëŠ¥ ë°ì´í„°ì„¸íŠ¸ì™€ ì›ë˜ ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì˜ˆì œ ë°ì´í„°ì„¸íŠ¸ë¥¼ ì‚´í´ë´ì•¼ í•˜ë¯€ë¡œ ì¡°ê¸ˆ ë” í•„ìš”í•˜ë¯€ë¡œ í›ˆë ¨ ì¤‘ì— ì •ê¸°ì ì¸ í‰ê°€ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. . í›ˆë ¨ì´ ëë‚œ í›„ì— ê²°ê³¼ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œë§Œ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.

`compute_metrics()` í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼í•œ ë‹¨ê³„ë¥¼ ê·¸ë£¹í™”í•©ë‹ˆë‹¤. ìœ íš¨í•œ ë‹µë³€ì´ ë‚˜ì˜¤ì§€ ì•ŠëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì‘ì€ ê²€ì‚¬ë§Œ ì¶”ê°€í•©ë‹ˆë‹¤(ì´ ê²½ìš° ë¹ˆ ë¬¸ìì—´ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤).

{:else}

ì´ì œ ë°©ê¸ˆ ìˆ˜í–‰í•œ ëª¨ë“  ì‘ì—…ì„ ëª¨ë¸ í•™ìŠµ í›„ ì‚¬ìš©í•  `compute_metrics()` í•¨ìˆ˜ì— ë„£ì–´ ë³´ê² ìŠµë‹ˆë‹¤. ì˜¤í”„ì…‹ì— ëŒ€í•œ ê¸°ëŠ¥ ë°ì´í„°ì„¸íŠ¸ì™€ ì›ë˜ ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì˜ˆì œ ë°ì´í„°ì„¸íŠ¸ì—ì„œ ì‚´í´ë´ì•¼ í•˜ë¯€ë¡œ ì¶œë ¥ ë¡œì§“ë³´ë‹¤ ì¡°ê¸ˆ ë” ë§ì€ ê²ƒì„ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.

{/if}

```python
from tqdm.auto import tqdm


def compute_metrics(start_logits, end_logits, features, examples):
    example_to_features = collections.defaultdict(list)
    for idx, feature in enumerate(features):
        example_to_features[feature["example_id"]].append(idx)

    predicted_answers = []
    for example in tqdm(examples):
        example_id = example["id"]
        context = example["context"]
        answers = []

        # Loop through all features associated with that example
        for feature_index in example_to_features[example_id]:
            start_logit = start_logits[feature_index]
            end_logit = end_logits[feature_index]
            offsets = features[feature_index]["offset_mapping"]

            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()
            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()
            for start_index in start_indexes:
                for end_index in end_indexes:
                    # Skip answers that are not fully in the context
                    if offsets[start_index] is None or offsets[end_index] is None:
                        continue
                    # Skip answers with a length that is either < 0 or > max_answer_length
                    if (
                        end_index < start_index
                        or end_index - start_index + 1 > max_answer_length
                    ):
                        continue

                    answer = {
                        "text": context[offsets[start_index][0] : offsets[end_index][1]],
                        "logit_score": start_logit[start_index] + end_logit[end_index],
                    }
                    answers.append(answer)

        # Select the answer with the best score
        if len(answers) > 0:
            best_answer = max(answers, key=lambda x: x["logit_score"])
            predicted_answers.append(
                {"id": example_id, "prediction_text": best_answer["text"]}
            )
        else:
            predicted_answers.append({"id": example_id, "prediction_text": ""})

    theoretical_answers = [{"id": ex["id"], "answers": ex["answers"]} for ex in examples]
    return metric.compute(predictions=predicted_answers, references=theoretical_answers)
```

ìš°ë¦¬ì˜ ì˜ˆì¸¡ëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
compute_metrics(start_logits, end_logits, eval_set, small_eval_set)
```

```python out
{'exact_match': 83.0, 'f1': 88.25}
```

ì¢‹ì•„ ë³´ì—¬! ì´ì œ ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤.

### ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •[[fine-tuning-the-model]]

{#if fw === 'pt'}

ì´ì œ ëª¨ë¸ì„ í›ˆë ¨í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì „ê³¼ ê°™ì´ `AutoModelForQuestionAnswering` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¨¼ì € ìƒì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤.

```python
model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)
```

{:else}

ì´ì œ ëª¨ë¸ì„ í›ˆë ¨í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì „ê³¼ ê°™ì´ `TFAutoModelForQuestionAnswering` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¨¼ì € ìƒì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤.

```python
model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)
```

{/if}

í‰ì†Œì™€ ê°™ì´ ì¼ë¶€ ê°€ì¤‘ì¹˜(ì‚¬ì „ í›ˆë ¨ í—¤ë“œì˜ ê°€ì¤‘ì¹˜)ê°€ ì‚¬ìš©ë˜ì§€ ì•Šê³  ì¼ë¶€ ê°€ì¤‘ì¹˜(ì§ˆë¬¸ ì‘ë‹µ í—¤ë“œì˜ ê°€ì¤‘ì¹˜)ê°€ ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”ëœë‹¤ëŠ” ê²½ê³ ê°€ í‘œì‹œë©ë‹ˆë‹¤. ì´ì œ ìµìˆ™í•´ì¡Œì„ ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŠ” ì´ ëª¨ë¸ì´ ì•„ì§ ì‚¬ìš©ë  ì¤€ë¹„ê°€ ë˜ì§€ ì•Šì•˜ìœ¼ë©° ë¯¸ì„¸ ì¡°ì •ì´ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ì œ ê³§ ê·¸ë ‡ê²Œ í•˜ê²Œ ë˜ì–´ ë‹¤í–‰ì…ë‹ˆë‹¤!

ëª¨ë¸ì„ í—ˆë¸Œì— í‘¸ì‹œí•˜ë ¤ë©´ Hugging Faceì— ë¡œê·¸ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ë…¸íŠ¸ë¶ì—ì„œ ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ê²½ìš° ë¡œê·¸ì¸ ìê²© ì¦ëª…ì„ ì…ë ¥í•  ìˆ˜ ìˆëŠ” ìœ„ì ¯ì„ í‘œì‹œí•˜ëŠ” ë‹¤ìŒ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from huggingface_hub import notebook_login

notebook_login()
```

ë…¸íŠ¸ë¶ì—ì„œ ì‘ì—…í•˜ì§€ ì•ŠëŠ” ê²½ìš° í„°ë¯¸ë„ì— ë‹¤ìŒ ì¤„ì„ ì…ë ¥í•˜ì„¸ìš”.

```bash
huggingface-cli login
```

{#if fw === 'pt'}

ì´ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ 'TrainingArguments'ë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•  ë•Œ ë§í–ˆë“¯ì´ `compute_metrics()` í•¨ìˆ˜ì˜ ì„œëª…ìœ¼ë¡œ ì¸í•´ ì¼ë°˜ì ì¸ í‰ê°€ ë£¨í”„ë¥¼ ê°€ì§ˆ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ 'Trainer'ì˜ ìì²´ í•˜ìœ„ í´ë˜ìŠ¤ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤([ì§ˆë¬¸ ë‹µë³€ ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸](https://github.com/huggingface/transformers/blob/master/examples/pytorch/question-ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì ‘ê·¼ ë°©ì‹). Answering/trainer_qa.py)), í•˜ì§€ë§Œ ì´ ì„¹ì…˜ì—ì„œëŠ” ë‚´ìš©ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ëŒ€ì‹  ì—¬ê¸°ì—ì„œëŠ” í›ˆë ¨ì´ ëë‚  ë•Œë§Œ ëª¨ë¸ì„ í‰ê°€í•˜ê³  ì•„ë˜ì˜ "ì‚¬ìš©ì ì •ì˜ í›ˆë ¨ ë£¨í”„"ì—ì„œ ì •ê¸°ì ì¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ì´ê²ƒì€ ì‹¤ì œë¡œ `Trainer` APIê°€ í•œê³„ë¥¼ ë³´ì—¬ì£¼ê³  ğŸ¤— Accelerate ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¹›ì„ ë°œí•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©ì ì •ì˜í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆì§€ë§Œ ì™„ì „íˆ ë…¸ì¶œëœ í›ˆë ¨ ë£¨í”„ë¥¼ ì¡°ì •í•˜ëŠ” ê²ƒì€ ì‰½ìŠµë‹ˆë‹¤.

'TrainingArguments'ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

```python
from transformers import TrainingArguments

args = TrainingArguments(
    "bert-finetuned-squad",
    evaluation_strategy="no",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    push_to_hub=True,
)
```

ìš°ë¦¬ëŠ” ì´ì „ì— ì´ë“¤ ì¤‘ ëŒ€ë¶€ë¶„ì„ ë³¸ ì ì´ ìˆìŠµë‹ˆë‹¤. ëª‡ ê°€ì§€ í•˜ì´í¼ ë§¤ê°œë³€ìˆ˜(ì˜ˆ: í•™ìŠµ ì†ë„, í•™ìŠµí•˜ëŠ” ì—í¬í¬ ìˆ˜, ì¼ë¶€ ê°€ì¤‘ì¹˜ ê°ì†Œ)ë¥¼ ì„¤ì •í•˜ê³  ëª¨ë“  ì—í¬í¬ê°€ ëë‚  ë•Œ ëª¨ë¸ì„ ì €ì¥í•˜ê³  ì‹¶ë‹¤ê³  í‘œì‹œí•˜ê³  í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. , ê²°ê³¼ë¥¼ ëª¨ë¸ í—ˆë¸Œì— ì—…ë¡œë“œí•˜ì„¸ìš”. ë˜í•œ 'fp16=True'ë¥¼ ì‚¬ìš©í•˜ì—¬ í˜¼í•© ì •ë°€ë„ êµìœ¡ì„ í™œì„±í™”í•©ë‹ˆë‹¤. ìµœì‹  GPUì—ì„œ êµìœ¡ ì†ë„ë¥¼ í¬ê²Œ ë†’ì¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

{:else}

ì´ì œ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ TF ë°ì´í„°ì„¸íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” ê°„ë‹¨í•œ ê¸°ë³¸ ë°ì´í„° ì¡°í•©ê¸°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from transformers import DefaultDataCollator

data_collator = DefaultDataCollator(return_tensors="tf")
```

ì´ì œ í‰ì†ŒëŒ€ë¡œ ë°ì´í„°ì„¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```python
tf_train_dataset = model.prepare_tf_dataset(
    train_dataset,
    collate_fn=data_collator,
    shuffle=True,
    batch_size=16,
)
tf_eval_dataset = model.prepare_tf_dataset(
    validation_dataset,
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)
```

ë‹¤ìŒìœ¼ë¡œ í›ˆë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•˜ê³  ëª¨ë¸ì„ ì»´íŒŒì¼í•©ë‹ˆë‹¤.

```python
from transformers import create_optimizer
from transformers.keras_callbacks import PushToHubCallback
import tensorflow as tf

# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied
# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,
# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.
num_train_epochs = 3
num_train_steps = len(tf_train_dataset) * num_train_epochs
optimizer, schedule = create_optimizer(
    init_lr=2e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)

# Train in mixed-precision float16
tf.keras.mixed_precision.set_global_policy("mixed_float16")
```

ë§ˆì§€ë§‰ìœ¼ë¡œ `model.fit()`ì„ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ê° ì—í¬í¬ í›„ì— 'PushToHubCallback'ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í—ˆë¸Œì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.

{/if}

ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì €ì¥ì†ŒëŠ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ìˆê³  ì„¤ì •í•œ ì¶œë ¥ ë””ë ‰í„°ë¦¬ì˜ ì´ë¦„ì„ ë”°ì„œ ëª…ëª…ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ì˜ ê²½ìš°ì—ëŠ” `"sgugger/bert-finetuned-squad"`ì— ìˆìŠµë‹ˆë‹¤. `hub_model_id`ë¥¼ ì „ë‹¬í•˜ì—¬ ì´ë¥¼ ì¬ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ëª¨ë¸ì„ `huggingface_course` ì¡°ì§ì— í‘¸ì‹œí•˜ê¸° ìœ„í•´ `hub_model_id="huggingface_course/bert-finetuned-squad"`(ì´ ì„¹ì…˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ì—°ê²°í•œ ëª¨ë¸)ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

{#if fw === 'pt'}

<Tip>

ğŸ’¡ ì‚¬ìš© ì¤‘ì¸ ì¶œë ¥ ë””ë ‰í„°ë¦¬ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš° í‘¸ì‹œí•˜ë ¤ëŠ” ì €ì¥ì†Œì˜ ë¡œì»¬ ë³µì œë³¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤(ë”°ë¼ì„œ `Trainer`ë¥¼ ì •ì˜í•  ë•Œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ìƒˆ ì´ë¦„ì„ ì„¤ì •í•˜ì„¸ìš”).

</Tip>

ë§ˆì§€ë§‰ìœ¼ë¡œ ëª¨ë“  ê²ƒì„ `Trainer` í´ë˜ìŠ¤ì— ì „ë‹¬í•˜ê³  í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.

```python
from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=validation_dataset,
    tokenizer=tokenizer,
)
trainer.train()
```

{:else}

```python
from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(output_dir="bert-finetuned-squad", tokenizer=tokenizer)

# We're going to do validation afterwards, so no validation mid-training
model.fit(tf_train_dataset, callbacks=[callback], epochs=num_train_epochs)
```

{/if}

í›ˆë ¨ì´ ì§„í–‰ë˜ëŠ” ë™ì•ˆ ëª¨ë¸ì´ ì €ì¥ë  ë•Œë§ˆë‹¤(ì—¬ê¸°ì„œëŠ” ë§¤ ì—í¬í¬ë§ˆë‹¤) ë°±ê·¸ë¼ìš´ë“œì—ì„œ í—ˆë¸Œì— ì—…ë¡œë“œë©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ í•„ìš”í•œ ê²½ìš° ë‹¤ë¥¸ ì¥ë¹„ì—ì„œ í›ˆë ¨ì„ ì¬ê°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ì²´ í›ˆë ¨ì—ëŠ” ì‹œê°„ì´ ê±¸ë¦¬ë¯€ë¡œ(Titan RTXì˜ ê²½ìš° 1ì‹œê°„ ë‚¨ì§“) ì»¤í”¼ë¥¼ ë§ˆì‹œê±°ë‚˜ ì§„í–‰í•˜ëŠ” ë™ì•ˆ ë” ì–´ë ¤ì› ë˜ ê³¼ì •ì˜ ì¼ë¶€ ë¶€ë¶„ì„ ë‹¤ì‹œ ì½ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì²« ë²ˆì§¸ ì—í¬í¬ê°€ ì™„ë£Œë˜ìë§ˆì í—ˆë¸Œì— ì¼ë¶€ ê°€ì¤‘ì¹˜ê°€ ì—…ë¡œë“œëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆìœ¼ë©° í•´ë‹¹ í˜ì´ì§€ì—ì„œ ëª¨ë¸ì„ ê°€ì§€ê³  ë†€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

{#if fw === 'pt'}

í›ˆë ¨ì´ ì™„ë£Œë˜ë©´ ë§ˆì¹¨ë‚´ ëª¨ë¸ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ê·¸ë¦¬ê³  ê³„ì‚° ì‹œê°„ì„ ì•„ë¬´ê²ƒë„ ë‚­ë¹„í•˜ì§€ ì•Šê¸°ë¥¼ ë°”ëë‹ˆë‹¤). 'Trainer'ì˜ 'predict()' ë©”ì„œë“œëŠ” ì²« ë²ˆì§¸ ìš”ì†Œê°€ ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ë˜ëŠ” íŠœí”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤(ì—¬ê¸°ì„œëŠ” ì‹œì‘ ë° ì¢…ë£Œ ë¡œì§“ê³¼ ìŒ). ì´ê²ƒì„ `compute_metrics()` í•¨ìˆ˜ë¡œ ë³´ëƒ…ë‹ˆë‹¤:

```python
predictions, _, _ = trainer.predict(validation_dataset)
start_logits, end_logits = predictions
compute_metrics(start_logits, end_logits, validation_dataset, raw_datasets["validation"])
```

{:else}

í›ˆë ¨ì´ ì™„ë£Œë˜ë©´ ë§ˆì¹¨ë‚´ ëª¨ë¸ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ê·¸ë¦¬ê³  ê³„ì‚° ì‹œê°„ì„ ì•„ë¬´ê²ƒë„ ë‚­ë¹„í•˜ì§€ ì•Šê¸°ë¥¼ ë°”ëë‹ˆë‹¤). `model`ì˜ `predict()` ë©”ì„œë“œëŠ” ì˜ˆì¸¡ì„ ê°€ì ¸ì˜¤ëŠ” ì‘ì—…ì„ ë‹´ë‹¹í•˜ë©° ì•ì„œ `compute_metrics()` í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ëŠ” ëª¨ë“  ë…¸ë ¥ì„ ê¸°ìš¸ì˜€ìœ¼ë¯€ë¡œ ê²°ê³¼ë¥¼ í•œ ì¤„ë¡œ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
predictions = model.predict(tf_eval_dataset)
compute_metrics(
    predictions["start_logits"],
    predictions["end_logits"],
    validation_dataset,
    raw_datasets["validation"],
)
```

{/if}

```python out
{'exact_match': 81.18259224219489, 'f1': 88.67381321905516}
```

ì—„ì²­ë‚œ! ë¹„êµí•´ ë³´ë©´, ì´ ëª¨ë¸ì— ëŒ€í•´ BERT ê¸°ì‚¬ì— ë³´ê³ ëœ ê¸°ì¤€ ì ìˆ˜ëŠ” 80.8ê³¼ 88.5ì´ë¯€ë¡œ ìš°ë¦¬ê°€ ìˆì–´ì•¼ í•  ìœ„ì¹˜ì— ìˆìŠµë‹ˆë‹¤.

{#if fw === 'pt'}

ë§ˆì§€ë§‰ìœ¼ë¡œ `push_to_hub()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ìµœì‹  ë²„ì „ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.

```py
trainer.push_to_hub(commit_message="Training complete")
```

ê²€ì‚¬í•˜ë ¤ëŠ” ê²½ìš° ë°©ê¸ˆ ìˆ˜í–‰í•œ ì»¤ë°‹ì˜ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤.

```python out
'https://huggingface.co/sgugger/bert-finetuned-squad/commit/9dcee1fbc25946a6ed4bb32efb1bd71d5fa90b68'
```

`Trainer`ë„ ëª¨ë“  í‰ê°€ ê²°ê³¼ë¥¼ ë‹´ì€ ëª¨ë¸ ì¹´ë“œ ì´ˆì•ˆì„ ì‘ì„±í•´ ì—…ë¡œë“œí•œë‹¤.

{/if}

ì´ ë‹¨ê³„ì—ì„œëŠ” ëª¨ë¸ í—ˆë¸Œì˜ ì¶”ë¡  ìœ„ì ¯ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ì¹œêµ¬, ê°€ì¡± ë° ì¢‹ì•„í•˜ëŠ” ì• ì™„ë™ë¬¼ê³¼ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ ì‘ë‹µ ì‘ì—…ì—ì„œ ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •í–ˆìŠµë‹ˆë‹¤. ì¶•í•˜í•©ë‹ˆë‹¤!

<Tip>

âœï¸ **ë‹¹ì‹  ì°¨ë¡€ì…ë‹ˆë‹¤!** ë‹¤ë¥¸ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•´ ì´ ì‘ì—…ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!

</Tip>

{#if fw === 'pt'}

í›ˆë ¨ ë£¨í”„ì— ëŒ€í•´ ì¢€ ë” ê¹Šì´ ì•Œê³  ì‹¶ë‹¤ë©´ ì´ì œ ğŸ¤— Accelerateë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì¼í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

## ë§ì¶¤í˜• í›ˆë ¨ ë£¨í”„[[a-custom-training-loop]]

ì´ì œ ì „ì²´ í›ˆë ¨ ë£¨í”„ë¥¼ ì‚´í´ë³´ê³  í•„ìš”í•œ ë¶€ë¶„ì„ ì‰½ê²Œ ì‚¬ìš©ì ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í‰ê°€ ë£¨í”„ë¥¼ ì œì™¸í•˜ë©´ [3ì¥](/course/chapter3/4)ì˜ í›ˆë ¨ ë£¨í”„ì™€ ë§¤ìš° ë¹„ìŠ·í•´ ë³´ì…ë‹ˆë‹¤. ë” ì´ìƒ `Trainer` í´ë˜ìŠ¤ì˜ ì œì•½ì„ ë°›ì§€ ì•Šìœ¼ë¯€ë¡œ ëª¨ë¸ì„ ì •ê¸°ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### í›ˆë ¨ì„ ìœ„í•œ ëª¨ë“  ì¤€ë¹„[[preparing-everything-for-training]]

ë¨¼ì € ë°ì´í„°ì„¸íŠ¸ì—ì„œ `DataLoader`ë¥¼ ë¹Œë“œí•´ì•¼ í•©ë‹ˆë‹¤. í•´ë‹¹ ë°ì´í„° ì„¸íŠ¸ì˜ í˜•ì‹ì„ `"torch"`ë¡œ ì„¤ì •í•˜ê³  ëª¨ë¸ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²€ì¦ ì„¸íŠ¸ì˜ ì—´ì„ ì œê±°í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ Transformersì—ì„œ ì œê³µí•˜ëŠ” `default_data_collator`ë¥¼ `collate_fn`ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  í›ˆë ¨ ì„¸íŠ¸ë¥¼ ì„ì„ ìˆ˜ ìˆì§€ë§Œ ê²€ì¦ ì„¸íŠ¸ëŠ” ì„ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

```py
from torch.utils.data import DataLoader
from transformers import default_data_collator

train_dataset.set_format("torch")
validation_set = validation_dataset.remove_columns(["example_id", "offset_mapping"])
validation_set.set_format("torch")

train_dataloader = DataLoader(
    train_dataset,
    shuffle=True,
    collate_fn=default_data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    validation_set, collate_fn=default_data_collator, batch_size=8
)
```

ë‹¤ìŒìœ¼ë¡œ ëª¨ë¸ì„ ë‹¤ì‹œ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ì—¬ ì´ì „ë¶€í„° ë¯¸ì„¸ ì¡°ì •ì„ ê³„ì†í•˜ì§€ ì•Šê³  BERT ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì—ì„œ ë‹¤ì‹œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

```py
model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)
```

ê·¸ëŸ° ë‹¤ìŒ ìµœì í™” í”„ë¡œê·¸ë¨ì´ í•„ìš”í•©ë‹ˆë‹¤. í‰ì†Œì™€ ê°™ì´ ìš°ë¦¬ëŠ” Adamê³¼ ë¹„ìŠ·í•˜ì§€ë§Œ ê°€ì¤‘ì¹˜ ê°ì†Œê°€ ì ìš©ë˜ëŠ” ë°©ì‹ì„ ìˆ˜ì •í•œ ê³ ì „ì ì¸ 'AdamW'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

```py
from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)
```

í•´ë‹¹ ê°œì²´ê°€ ëª¨ë‘ ìˆìœ¼ë©´ `accelerator.prepare()` ë©”ì„œë“œë¡œ ë³´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Colab ë…¸íŠ¸ë¶ì—ì„œ TPUë¥¼ í•™ìŠµì‹œí‚¤ë ¤ë©´ ì´ ì½”ë“œë¥¼ ëª¨ë‘ í•™ìŠµ í•¨ìˆ˜ë¡œ ì´ë™í•´ì•¼ í•˜ë©° 'ê°€ì†ê¸°'ë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ëŠ” ì…€ì„ ì‹¤í–‰í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. `fp16=True`ë¥¼ `Accelerator`ì— ì „ë‹¬í•˜ì—¬ í˜¼í•© ì •ë°€ë„ í›ˆë ¨ì„ ê°•ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ë˜ëŠ” ì½”ë“œë¥¼ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‹¤í–‰í•˜ëŠ” ê²½ìš° ğŸ¤— Accelerate `config`ë¥¼ ì ì ˆí•˜ê²Œ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”).

```py
from accelerate import Accelerator

accelerator = Accelerator(fp16=True)
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)
```

ì´ì „ ì„¹ì…˜ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´, `accelerator.prepare()` ë©”ì„œë“œë¥¼ ê±°ì¹œ í›„ í›ˆë ¨ ë‹¨ê³„ ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ `train_dataloader` ê¸¸ì´ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì „ ì„¹ì…˜ê³¼ ë™ì¼í•œ ì„ í˜• ì¼ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

```py
from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)
```

ëª¨ë¸ì„ í—ˆë¸Œì— í‘¸ì‹œí•˜ë ¤ë©´ ì‘ì—… í´ë”ì— `Repository` ê°œì²´ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤. ì•„ì§ ë¡œê·¸ì¸í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¨¼ì € Hugging Face Hubì— ë¡œê·¸ì¸í•˜ì„¸ìš”. ëª¨ë¸ì— ì œê³µí•˜ë ¤ëŠ” ëª¨ë¸ IDì—ì„œ ì €ì¥ì†Œ ì´ë¦„ì„ ê²°ì •í•  ê²ƒì…ë‹ˆë‹¤(`repo_name`ì„ ì›í•˜ëŠ” ê²ƒìœ¼ë¡œ ììœ ë¡­ê²Œ ë°”ê¾¸ì‹­ì‹œì˜¤. ì‚¬ìš©ì ì´ë¦„ë§Œ í¬í•¨í•˜ë©´ ë©ë‹ˆë‹¤. ì´ëŠ” `get_full_repo_name()` í•¨ìˆ˜ê°€ ìˆ˜í–‰í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤. ):

```py
from huggingface_hub import Repository, get_full_repo_name

model_name = "bert-finetuned-squad-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name
```

```python out
'sgugger/bert-finetuned-squad-accelerate'
```

ê·¸ëŸ° ë‹¤ìŒ í•´ë‹¹ ì €ì¥ì†Œë¥¼ ë¡œì»¬ í´ë”ì— ë³µì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ì´ ë¡œì»¬ í´ë”ëŠ” ì‘ì—… ì¤‘ì¸ ì €ì¥ì†Œì˜ ë³µì œë³¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

```py
output_dir = "bert-finetuned-squad-accelerate"
repo = Repository(output_dir, clone_from=repo_name)
```

ì´ì œ `repo.push_to_hub()` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ `output_dir`ì— ì €ì¥í•œ ëª¨ë“  í•­ëª©ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê° ì‹œëŒ€ê°€ ëë‚  ë•Œ ì¤‘ê°„ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
## í›ˆë ¨ ë£¨í”„[[training-loop]]

ì´ì œ ì „ì²´ í›ˆë ¨ ë£¨í”„ë¥¼ ì‘ì„±í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. í›ˆë ¨ ì§„í–‰ ë°©ì‹ì„ ë”°ë¥´ê¸° ìœ„í•´ ì§„í–‰ë¥  í‘œì‹œì¤„ì„ ì •ì˜í•œ í›„ ë£¨í”„ëŠ” ì„¸ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

- 'train_dataloader'ì— ëŒ€í•œ ê³ ì „ì ì¸ ë°˜ë³µì¸ í›ˆë ¨ ìì²´ëŠ” ëª¨ë¸ì„ í†µí•œ ì •ë°©í–¥ ì „ë‹¬, ê·¸ëŸ° ë‹¤ìŒ ì—­ë°©í–¥ ì „ë‹¬ ë° ìµœì í™” ë‹¨ê³„ì…ë‹ˆë‹¤.
- 'start_logits' ë° 'end_logits'ì— ëŒ€í•œ ëª¨ë“  ê°’ì„ NumPy ë°°ì—´ë¡œ ë³€í™˜í•˜ê¸° ì „ì— ìˆ˜ì§‘í•˜ëŠ” í‰ê°€ì…ë‹ˆë‹¤. í‰ê°€ ë£¨í”„ê°€ ì™„ë£Œë˜ë©´ ëª¨ë“  ê²°ê³¼ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤. 'ê°€ì†ê¸°'ê°€ ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ ë™ì¼í•œ ìˆ˜ì˜ ì˜ˆì œë¥¼ ê°–ë„ë¡ í•˜ê¸° ìœ„í•´ ëì— ëª‡ ê°œì˜ ìƒ˜í”Œì„ ì¶”ê°€í–ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜ë¼ì•¼ í•©ë‹ˆë‹¤.
- ì €ì¥ ë° ì—…ë¡œë“œ. ë¨¼ì € ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì €ì¥í•œ ë‹¤ìŒ `repo.push_to_hub()`ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. ì´ì „ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ `blocking=False` ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ğŸ¤— Hub ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ë¹„ë™ê¸° í”„ë¡œì„¸ìŠ¤ë¥¼ í‘¸ì‹œí•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ í›ˆë ¨ì´ ì •ìƒì ìœ¼ë¡œ ê³„ì†ë˜ê³  ì´ (ê¸´) ëª…ë ¹ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.

í›ˆë ¨ ë£¨í”„ì˜ ì „ì²´ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```py
from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Training
    model.train()
    for step, batch in enumerate(train_dataloader):
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    start_logits = []
    end_logits = []
    accelerator.print("Evaluation!")
    for batch in tqdm(eval_dataloader):
        with torch.no_grad():
            outputs = model(**batch)

        start_logits.append(accelerator.gather(outputs.start_logits).cpu().numpy())
        end_logits.append(accelerator.gather(outputs.end_logits).cpu().numpy())

    start_logits = np.concatenate(start_logits)
    end_logits = np.concatenate(end_logits)
    start_logits = start_logits[: len(validation_dataset)]
    end_logits = end_logits[: len(validation_dataset)]

    metrics = compute_metrics(
        start_logits, end_logits, validation_dataset, raw_datasets["validation"]
    )
    print(f"epoch {epoch}:", metrics)

    # Save and upload
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )
```

ğŸ¤— Accelerateë¡œ ì €ì¥ëœ ëª¨ë¸ì„ ì²˜ìŒìœ¼ë¡œ ë³´ëŠ” ê²½ìš°, ì ì‹œ ì‹œê°„ì„ ë‚´ì–´ í•´ë‹¹ ëª¨ë¸ê³¼ ê´€ë ¨ëœ ì„¸ ì¤„ì˜ ì½”ë“œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

```py
accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
```

The first line is self-explanatory: it tells all the processes to wait until everyone is at that stage before continuing. This is to make sure we have the same model in every process before saving. Then we grab the `unwrapped_model`, which is the base model we defined. The `accelerator.prepare()` method changes the model to work in distributed training, so it won't have the `save_pretrained()` method anymore; the `accelerator.unwrap_model()` method undoes that step. Lastly, we call `save_pretrained()` but tell that method to use `accelerator.save()` instead of `torch.save()`. 

Once this is done, you should have a model that produces results pretty similar to the one trained with the `Trainer`. You can check the model we trained using this code at [*huggingface-course/bert-finetuned-squad-accelerate*](https://huggingface.co/huggingface-course/bert-finetuned-squad-accelerate). And if you want to test out any tweaks to the training loop, you can directly implement them by editing the code shown above!

{/if}

## ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ ì‚¬ìš©[[using-the-fine-tuned-model]]

ì¶”ë¡  ìœ„ì ¯ì„ í†µí•´ ëª¨ë¸ í—ˆë¸Œì—ì„œ ë¯¸ì„¸ ì¡°ì •í•œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì´ë¯¸ ë³´ì—¬ë“œë ¸ìŠµë‹ˆë‹¤. `íŒŒì´í”„ë¼ì¸`ì—ì„œ ë¡œì»¬ë¡œ ì‚¬ìš©í•˜ë ¤ë©´ ëª¨ë¸ ì‹ë³„ìë§Œ ì§€ì •í•˜ë©´ ë©ë‹ˆë‹¤.
```py
from transformers import pipeline

# Replace this with your own checkpoint
model_checkpoint = "huggingface-course/bert-finetuned-squad"
question_answerer = pipeline("question-answering", model=model_checkpoint)

context = """
ğŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration
between them. It's straightforward to train your models with one before loading them for inference with the other.
"""
question = "Which deep learning libraries back ğŸ¤— Transformers?"
question_answerer(question=question, context=context)
```

```python out
{'score': 0.9979003071784973,
 'start': 78,
 'end': 105,
 'answer': 'Jax, PyTorch and TensorFlow'}
```

ì—„ì²­ë‚œ! ìš°ë¦¬ ëª¨ë¸ì€ ì´ íŒŒì´í”„ë¼ì¸ì˜ ê¸°ë³¸ ëª¨ë¸ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!